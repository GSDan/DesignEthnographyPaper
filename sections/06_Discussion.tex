\section{Discussion}

\subsection{Embedded values in the system}

Analysing and querying the design of technological systems can give insights into the designer's priorities, attitudes and assumptions \citep{Star1999}. We argue that these findings highlight how the design decisions made during this process are indicative of each stakeholder's priorities and their perceptions of the women domestic workers.

There are multiple elements within the system's design and observations made during the design process which suggest that \PC{} had low expectations of the workers. For example, the `tracking calls' during the `travelling to the job' stage were perceived by \PC{} to be a necessary inclusion to prompt workers to arrive at client's houses on time---even after a high success rate during the `Human IVR' deployment (where calls the calls had been removed due to complaints from the workers), \PCTwo{} was concerned that workers would not leave on time if the calls were not coming from a human operator. Another example was the belief that the women would be confused if given the ratings of clients when offered work, and that such decisions should be made algorithmically `\textit{from the back-end}'. These low expectations and unequal provision of information contribute towards a final design where the worker has little power: as seen in analyses of other gig-economy systems \cite{martin2016, Hara2018, carlos2021, lee2015}, a lack of information flow and opaque, algorithmic control often results in a system where the worker has less power than other parties. Furthermore, there are multiple elements of the system which treat the workers as a product or commodity, such as the use of language like `Premium' and `Basic' maids in the app's interface. Such objectification, combined with the intrusive use of technology (i.e. the `tracking calls'), is reminiscent of how crowdworkers are framed: where workers are likened to `troublesome components' to be controlled, rather than human stakeholders to be designed for \cite{martin2016}.

Further inferences can be drawn regarding \PC's priorities---as noted, \PC{} are principally a for-profit company, and the system's design reflects their prioritisation of clients' interests over those of the workers. This is evident through design decisions both benign (e.g. that the worker is called to accept a job before the client is called to confirm it is legitimate; that workers receive automated calls, while customers are called by human operators) and those that have serious potential consequences (e.g. that workers' ratings of clients were not provided during IVR calls offering jobs, nor being considered by the algorithm during `Human IVR' deployment; that \PC{} had few concerns related to safety when sharing workers' phone numbers with clients). As Lee argues, supply-demand orientated algorithmic controls frequently do not account for human factors \citep{lee2015}: such issues are further evident in this system, where workers are expected to be ready to leave their home at a moment's notice, under the assumption that responsibilities such as childcare or housework obligations would have already been completed---prioritising keeping client's waiting time to a minimum. The requirement that workers stay in the client's house until \PC{} has received payment---with the onus being on the worker to follow-up on any apparent issues---again suggests that little thought had been given to the workers' experiences of the system, and serves as an example of the workers themselves being the site of engagement between the client and the company, placing additional focus and pressure upon the worker's presence and emotional performance \cite{raval2016}. These issues make it clear that the system's human-centred design focus is on the users, not the workers, further evidenced by \PC{}'s platform being built around technology that the client has access to but the worker does not, with the IVR system's existence being an attempt to work around this core inequality.

While \NGO{} made fewer contributions to the design, they were consistent in evidencing their stated goal of improving the well-being of women domestic workers. Suggestions such as the algorithm accounting for workers' ratings of clients and the inclusion of safety reminders had a clear focus on improving the workers' safety and agency. However, within the final design the focus on women's empowerment was lost: by the end of the design process, the women were no longer the priority. As the party with the platform and task of creating the implementation, \PC{} had the most control over the system's final design. As a for-profit company \PC{}'s priority was understandably to make money, and so the focus of the project naturally shifted from the women being the cause to being the product---no longer a priority, but a commodity within the design process to support an organisation's profit. We argue that these findings highlight the importance of designers being aware of their own values, priorities and assumptions: as Martin et al. argue, technology interventions introduced without care into gig-economy ecosystems have the potential to reify existing inequalities or create new ones \cite{martin2016}. Before attempting to introduce what we think are worker-centred interventions \cite{carlos2021}, designers should reflect on their own interests, and how they compare and contrast with those who will be affected by the systems we create.


\subsection{Highlighting Priorities through Technology Limitations}

As noted previously, IVR as is a technology medium with inherent design limitations that require designers to go through a process of prioritisation: menus and messages are usually prescribed and largely static, meaning that decisions be made about what information and functionality the user is given access to; and messages are read out linearly and limited in length to avoid a tedious user experience: requiring judgements be made not only on the inclusion of information, but in what order it is presented. In this regard IVR is something of a blunt instrument, where the end-user is given little ability to work outside of the confines of the design space set out by its system designer. Due to these limitations, the choices of what information and functionality is included and excluded are strong indications of the designer's priorities and assumptions. 

In this study, we have been able to provide insights into how the stakeholders' values were embedded within the final system design. A significant number of these insights were resultant of questioning and critically analysing the usage of the IVR platform, and the inclusion and omission of pieces of information being given to workers through it. Furthermore, this process was shown to be realistically applicable in a practical setting: this study was undergone within a real-world, working context, gaining insights from the ongoing development of a private for-profit company's live infrastructure. While examining this infrastructure as outside stakeholders took a considerable amount of time due to the need for familiarisation, this could be expedited if performed by investigators already aware of the design space's context. We propose that introducing constraints in system design exercises could be used by designers and engineers as an efficient way of surfacing and reflecting upon what values they are prone to embed within their systems: even in real-world, for-profit contexts. If a project does not already feature a suitably constrained medium, constraints can be contrived through abstraction: previous work has shown the benefits of using mediums such as Lego for collaboration and the communication of complex ideas \cite{Cantoni2009}. Such techniques could be utilised to critique the values embedded into system infrastructures, such as algorithms, where complexity frequently leads to practical opacity, impeding productive critical analysis. As this study has shown, this would be a particularly useful in collaborative projects where parties may have different, even conflicting, agendas. As such a relationship is seemingly almost guaranteed between for-profit gig-economy companies and their employees, we argue that such steps should be taken by any platforms looking to develop a worker-centred perspective \citep{carlos2021}.

\subsection{Breaking the cycle of disempowerment}

********* TODO What Oxfam was attempting to do was to work ‘within the gig economy system’.  Obfuscation - empowerment within a framework of disempowerment. Grey wash? There are many companies currently starting up similar programs in BD and they wanted to get in a use HT as a ‘gold star example’ of how an ethical platform could be used. But - this process revealed how working within the established paradigm wouldn’t shift the cycle of disempowerment these women constantly faced. e.g. (1) Socio-cultural perceptions embedded in the system. e.g. class - the distrust of these women, the intention to track and surveil, privacy breaches.. whilst there were continuous discussions of ‘empowerment’, the underlying values and ideals around what these women represented wasn’t addressed. In fact - these values were reflected in decisions that were embedded in the platform design. **************

Platform cooperatives: an argument for working outside the system

************* TODO Significant argument to work outside the system - disrupt. e.g. Platform cooperativism - creating platforms that reflect the values of the people. This becomes about who they are designing for. *********

accountability in design decision making - who benefits from what part

suitability of `gig' platforms and attitudes towards design for full time work with hopes of advancement