\section{Related Work}

\subsection{Surfacing Values in Technology Design}

The critical analysis of stakeholders' human values to inform technology design and use has become an increasingly popular research subject within HCI \cite{shilton2018}, with contexts spanning from social media \cite{DeVito2021}, to education \cite{richardson2017} and games \cite{flanagan2014}. Traditionally, algorithms, platforms and databases have been discussed as if they are ethically neutral, and as a result values-based inquiry has been left outside of the scope of developers' design practice \cite{Shilton2013}. As the designs of systems and infrastructures can have implicit or explicit political qualities embedded within them \cite{winner1980}, the ethnographic study of such infrastructures can provide insights into designers' decision-making processes \cite{Star1999}. One of the most influential frameworks for approaching value-conscious design is Value Sensitive Design (VSD): an adaptable, tripartite methodology that uses theoretical, empirical, and technical approaches in combination with a guiding list of suggested values to scaffold philosophical analyses of systems or design spaces \cite{friedman2006}. VSD has been previously reconfigured to focus on empirical techniques, such as photo elicitation and defamiliarization, which can assist in the discovery of non-prescribed values \cite{LeDantec2009}. Such probes have been used to aid in the discovery of stakeholders' goals, priorities, preferences and expectations \cite{flanagan2014, GrowAGame}, or to support explicit and implicit discussions of participant values \cite{Alshehri2020}. Other approaches, such as socio-technical integration, utilise research methods such as semi-structured interviews with designers to promote ethical reflection upon design decisions \cite{fisher2007}. 

However, such values-oriented processes are not commonly deployed by small and medium-sized software development teams in commercial settings, given their reliance on specialist research techniques and a common perception of them being slow or unnecessary \cite{Shilton2013}. Within these environments, designers often act as advocates pushing for human-centred design, often espousing values in tension with their organization's own interests \cite{Chivukula2020}. Shilton argues that having a `values advocate' within an organisation can be a viable approach, but acknowledges arguments that having a single advocate risks the marginalization of other voices, and that the need for such roles can be difficult to justify to leadership \cite{shilton2018, manders2013, Borning2012}. While such approaches are effective ways of critically engaging with stakeholders' values \cite{DeVito2021}, the required time investment and knowledge of literature and methodology (e.g. designing probes, conducting interviews) effectively requires the presence of a researcher---an unreasonable expectation of smaller companies, who are often unlikely to even have dedicated UX designers due to the typical prioritisation of functionality over form, usability, and even ethics \cite{Ardito2014, Shilton2013}.

Shilton recommends the use of `values levers': informal practices that call attention to designed infrastructure, serving as effective entry points for value discussions during the process of technology development \cite{Shilton2013, shilton2018}. Whereas VSD provides grounded reasoning through theoretical, empirical and technical investigations for values-based design decisions, values levers instead act as provocations: prompting moments of reflection and (sometimes emotional) reaction rather than evidence-based reasoning with scientific rigour. While resulting arguments for design rationale may not hold up to academic scrutiny, this is likely to be a non-issue for many within commercial contexts, and is arguably counter-balanced by values levers requiring significantly less work. Examples of such levers include: designers and engineers self-testing their creations and encountering discomfort at how their data is used \cite{Shilton2013}; designers explaining their decision-making across disciplinary barriers, requiring re-framing and re-examination of practices \cite{shilton2018}; and online communities of mobile app developers reflecting upon why technical constraints are put in place by mobile platform holders \cite{shilton2019}. Such examples suggest that values levers can be introduced as effective prompts for reflection within a commercial development environment, without the need for interventions by specialist researchers. However, Shilton argues that in order for values levers to exist, they have to be deployed by practices and agents \cite{Shilton2013}. Outside of the examples given, little research has explored what practices could be used to purposefully deploy values levers within a commercial context to promote the discussion of values and practitioner reflection.

\subsection{The Gig Economy \& South Asia}

To lower costs and support scalability, gig economy platforms typically use algorithmic approaches to automate the allocation of the `most suitable' workers to jobs \cite{Wood2019}. In theory, this allows gig work platforms to offer high levels of flexibility and autonomy, as workers can ostensibly have control over when and where they work \cite{Wood2019, Balaram2017, carlos2021}. The success of ride-sharing and delivery services such as Uber has led to the `gig' model being explored in many other service industries \cite{Balaram2017}. However, the recent popularity of gig work has prompted both caution and criticism: the industry's focus on quantified worker ratings and algorithmic assignment has been shown to result in low pay, social isolation, and overwork \cite{Wood2019}. Questions have also been raised around whether current employment laws are capable of addressing workers' needs, such as sickness protection, when applied outside of traditional employment models: adding to fears of exploitation through a `race to the bottom' of cheap pricing and low-cost labour \cite{Taylor2017,Balaram2017}. 

Nevertheless, gig work has remained popular, particularly in South Asia: India and Bangladesh are amongst the fastest growing freelancer markets in the world \cite{Payoneer2019}. Ride sharing services are increasingly popular within Bangladesh \cite{islam2019} and their unregulated growth has encouraged tens of thousands of rural and suburban youths to migrate to metropolitan areas, prompting calls for regulatory action \cite{Fairwork2021}. Ahmed argues that those in Bangladesh without access to digital technologies cannot access these new employment opportunities \cite{Ahmed2020}, further deepening an existing digital divide and highlighting concerns around workers being underpaid, overworked, and constantly monitored \cite{Irani2013}. Minter argues that, while there is a need for governments to introduce enforceable labour standards, this will take time: suggesting that while government solutions are being negotiated, non-state actors should work with gig economy companies on formal agreements to support workers' fair treatment and identify current issues \cite{Minter2017}.


\subsection{HCI \& the Gig Economy }

The HCI research community's involvement in the gig economy can be traced back to its undiluted form, `crowdworking', where online workers are given microtasks and paid per acceptable completion. Such platforms have been previously used as cheap and easily accessible sources of research participants (e.g. \cite{mason2012conducting, mcnaney2016, Othman2017}). While early academic discourse frequently focused on improving such platforms' efficiencies, comparatively little investigation was taken into the workers themselves: their socio-economic status and the impact of the platforms' designs on them \cite{Jacques2019, Irani2013}.

Recent years have seen more critical, values-based analyses: Martin et al. note the dehumanising rhetoric surrounding crowd workers (e.g. `\textit{artificial artificial intelligence}', and `\textit{cogs in the machine}'), and how such terminology makes them easier to regard as `troublesome components' to be controlled, rather than real human stakeholders worthy of design considerations \cite{martin2016}. A common frustration relating to gig economy platforms is a lack of transparency: the deeper functioning of such systems (e.g. the specifics of work assignment algorithms) is often opaque to the worker, leading to worker frustration and a balance of power in favour of clients and platform holders \cite{martin2016}. Furthermore, gig economy platforms are generally not designed to support communications between workers, which has been identified as one factor limiting gig worker collective bargaining \cite{Hara2018}. This weak bargaining power leads to the pace of work being determined by direct demands from clients, heightened by a lack of job security and a frequent oversupply of labour \cite{Wood2019}. Lee et al. argue that increased transparency in the assignment process could elicit greater cooperation with work assignments, especially undesirable ones: because the current supply-demand control algorithms do not account for human factors (such as workers' capability and motivations), their use in motivating and controlling human behaviors created distrust of the system in workers \cite{lee2015}. Lee also noted that the practical opacity of a platform's algorithm can lead to workers resorting to speculation and sensemaking through external channels, such as with other workers on social media platforms \cite{lee2015}. Raval \& Dourish note that gig platforms' monetisation models frequently erase the distinction of work and `related work' (such as care labour), and that platforms place workers' own bodies and possessions as the sites of engagement between clients and corporations: placing additional focus on workers' emotional performance, bodily presence and timeliness \cite{raval2016}. This combination of opaque, quantified evaluation and an apparent accountability for every interaction creates a hyper-awareness of clients' ratings and the potential for psychological stress \cite{lee2015}.

Introducing technology interventions without care runs the risk of amplifying existing inequalities amongst workers, or even creating new power dynamics within a given platform's economy \cite{martin2016}. In response to these issues, Alvarez et al. call for a greater worker-centred perspective in the design of gig economy platforms, focusing on transparency, professional development, networking and an avoidance of power asymmetry \cite{carlos2021}. Designing the algorithms used by gig economy platforms to manage and assign workers in a human-centred approach will require practical methods of identifying the values and requirements of all stakeholders, including those of the designers and engineers \cite{lee2015}.