\section{Related Work}

\subsection{Surfacing Values in Technology Design}

The critical analysis of stakeholders' human values to inform technology design and use has become an increasingly popular research subject within HCI \cite{shilton2018}, with contexts spanning from social media \cite{DeVito2021}, to education \cite{richardson2017} and games \cite{flanagan2014}. Without intervention, algorithms, platforms and databases are often discussed as if they are ethically neutral, meaning that values-based inquiry is often left outside of the scope of developers' design practice \cite{Shilton2013}. As the designs of systems and infrastructures can have implicit or explicit political qualities embedded within them \cite{winner1980}, the ethnographic study of such infrastructures can provide insights into the designers' decision-making priorities \cite{Star1999}. One of the most influential frameworks for approaching value-conscious design is Value Sensitive Design (VSD): an adaptable, tripartite methodology that uses theoretical, empirical, and technical approaches in combination with a guiding list of suggested values to scaffold philosophical analyses of given systems or design spaces \cite{friedman2006}. VSD has been previously reconfigured to focus on empirical techniques, such as photo elicitation and defamiliarization, which can assist in the discovery of non-prescribed values \cite{LeDantec2009}. Such cultural probes have been used to aid in the discovery of stakeholders' goals, priorities, preferences and expectations \cite{flanagan2014, GrowAGame}, or to support explicit and implicit discussions of participant values \cite{Alshehri2020}. Other approaches, such as socio-technical integration, utilise research methods such as semi-structured interviews with designers to promote ethical reflection upon design decisions \cite{fisher2007}. 

However, values-oriented processes such as VSD are often unattractive within environments focusing on production and commercial interests, due to them relying on specialist research techniques or to a perception of them being slow or unnecessary \cite{Shilton2013}. Within these environments, designers often act as advocates pushing for human-centred design, often with espousing values in tension with their organization's own interests \cite{Chivukula2020}. Shilton argues that having a `values advocate' within an organisation can be a viable approach, but acknowledges arguments that having a single advocate risks the marginalization of other voices, and that the need for such roles can be difficult to justify to leadership \cite{shilton2018, manders2013, Borning2012}. While such approaches are effective ways of critically engaging with stakeholders' values \cite{DeVito2021}, the required time investment and knowledge of literature and methodology (e.g. designing probes, holding interviews) effectively requires the presence of a researcher---an unreasonable expectation of smaller companies, who are often unlikely to even have dedicated UX designers due to the common prioritisation of functionality over usability or philosophical considerations \cite{Ardito2014, Shilton2013}.

Shilton argues for the consideration of `values levers': informal practices that call attention to designed infrastructure, serving as effective entry points for value discussions during the process of technology development \cite{Shilton2013, shilton2018}. Given examples of such levers include: designers and engineers self-testing their created technology and encountering discomfort at how their data is used \cite{Shilton2013}; designers explaining their decision-making across disciplinary barriers, requiring re-framing and re-examination of practices \cite{shilton2018}; and online communities of mobile app developers reflecting upon why technical constraints are put in place by mobile platform holders \cite{shilton2019}. Such examples suggest that values levers can be introduced as effective prompts for reflection within a commercial development environment, without the need for interventions by specialist researchers. However, Shilton argues that in order for values levers to exist, they have to be deployed by practices and agents \cite{Shilton2013}. Outside of the examples given, little research has explored what practices could be used to purposefully deploy values levers within a commercial context to promote the discussion of values and practitioner reflection.

\subsection{The Gig Economy \& South Asia}

To lower costs and support scalability, gig economy platforms tend to place a focus on the allocation of `most suitable' workers per job by a set algorithm \cite{Wood2019}. This lack of overhead means that gig work platforms can offer a high level of flexibility and autonomy, as workers can ostensibly have control over when and where they work \cite{Wood2019, Balaram2017, carlos2021}. The success of ride-sharing and delivery services such as Uber has meant that the `gig' model is being explored in other service industries \cite{Balaram2017}. However, the recent popularity of gig work has attracted both caution and criticism: the industry's focus on quantified worker ratings and algorithmic assignment has been shown to result in low pay, social isolation and overwork \cite{Wood2019}. Questions have also been raised around if current employment laws are capable of addressing workers' needs such as sickness protection when applied outside of traditional employment models, adding to fears of exploitation through a `race to the bottom' of cheap pricing and low-cost labour \cite{Taylor2017,Balaram2017}. 

Nevertheless, gig work has remained popular, particularly in South Asia: India and Bangladesh are some of the fastest growing freelancer markets \cite{Payoneer2019}. Ride sharing services are increasingly popular within Bangladesh \cite{islam2019}, and their unregulated growth has encouraged tens of thousands of rural and suburban youths to migrate to metropolitan areas, prompting calls for government and social action \cite{Fairwork2021}. Ahmed argues that those in Bangladesh without access to digital technologies cannot access these new employment opportunities, deepening the digital divide, and highlights concerns around workers being underpaid, overworked and constantly monitored \cite{Ahmed2020, Irani2013}. Minter argues that while there is a need for governments to introduce enforceable labour standards, these will take time to introduce: suggesting that in the short-term, non-state actors should work with gig-economy companies on formal agreements to support workers' fair treatment while government solutions are being negotiated \cite{Minter2017}.


\subsection{HCI \& the Gig Economy }

The HCI research community's involvement in the gig economy can be traced back to its undiluted form, `crowdworking', where online workers are given microtasks and paid per acceptable completion. Such platforms have been previously used as cheap and easily accessible sources of research participants (e.g. \cite{mason2012conducting, mcnaney2016, Othman2017}). While academic discourse frequently focused on improving such platforms' efficiencies, comparatively little investigation was taken into the workers themselves: their socio-economic status and the impact of the platforms' designs on them \cite{Jacques2019, Irani2013}.

Recent years have seen more critical, values-based analyses: Martin et al. note the dehumanising rhetoric surrounding crowd workers (e.g. `artificial artificial intelligence', `cogs in the machine'), and how such terminology makes them easier to regard as `troublesome components' to be controlled, rather than real human stakeholders worthy of design considerations \cite{martin2016}. A common frustration relating to gig economy platforms is a lack of transparency: the deeper functioning of such systems (e.g. the specifics of work assignment algorithms) is often opaque to the worker, leading to worker frustration and a balance of power in favour of clients and platform holders \cite{martin2016}. Furthermore, gig economy platforms are frequently not designed to support communications between workers, which has been identified as one factor limiting gig worker collective bargaining \cite{Hara2018}. This weak bargaining power leads to the pace of work being determined by direct demands from clients, heightened by a lack of job security and a frequent oversupply of labour \cite{Wood2019}. Lee et al. argue that increased transparency in the assignment process could elicit greater cooperation with work assignments, especially undesirable ones: because the current supply-demand control algorithms do not account for human factors (such as workers' capability and motivations), their use in motivating and controlling human behaviors created distrust of the system in workers \cite{lee2015}. Raval \& Dourish note that gig platforms' monetisation models frequently erase the distinction of work and `related work' (such as care labour), and that platforms place workers' own bodies and possessions as the sites of engagement between clients and corporations: placing additional focus on workers' emotional performance, bodily presence and timeliness \cite{raval2016}. This combination of opaque, quantified evaluation and an apparent accountability for every interaction creates a hyper-awareness of clients' ratings and the potential for psychological stress \cite{lee2015}.

Introducing technology interventions without care runs the risk of reifying pre-existing inequalities amongst workers, or even creating new power dynamics within a given platform's economy \cite{martin2016}. In response to these issues, Alvarez et al. call for a greater worker-centred perspective in the design of gig economy platforms, focusing on transparency, professional development, networking and an avoidance of power asymmetry \cite{carlos2021}. Designing the algorithms used by gig economy platforms to manage and assign workers in a human-centred approach will require practical methods of identifying stakeholder values and requirements \cite{lee2015}.